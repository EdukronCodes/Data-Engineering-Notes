# 📄 Resume – Sagar | Azure Data Engineer (3+ YOE)

**Sagar Kumar**
📞 Phone: +91-98765-43210 | ✉️ Email: sagar.kumar@email.com
🌐 LinkedIn: linkedin.com/in/sagar-kumar-azure | 📍 Location: Bangalore, Karnataka

## Professional Summary

Azure Data Engineer with 3+ years of experience in building and optimizing data pipelines, ETL workflows, and cloud-based data platforms. Proficient in Azure Data Factory (ADF), Azure Databricks, Synapse Analytics, and Data Lake. Skilled in data modeling, SQL optimization, and big data processing to deliver reliable data solutions for analytics and business intelligence.

## Technical Skills

**Cloud & Data Platforms:** Azure Data Factory, Azure Databricks, Azure Synapse Analytics, Azure Data Lake (Gen2), Azure SQL Database

**Big Data & Processing:** PySpark, Apache Spark, Delta Lake, Azure HDInsight, Azure Stream Analytics

**Databases & Warehousing:** Azure SQL Database, Azure Cosmos DB, Azure Database for PostgreSQL, Azure Database for MySQL

**Programming & Scripting:** Python, SQL, Scala (basic)

**Data Modeling & ETL:** Star/Snowflake Schema, Slowly Changing Dimensions, Medallion Architecture

**Visualization:** Power BI, Azure Analysis Services

**Version Control & CI/CD:** Git, GitHub, Azure DevOps, Azure Repos

**Other Tools:** Docker, Azure Container Instances, Azure Kubernetes Service

## Professional Experience

### Azure Data Engineer
**[Company Name] – [Location]**
📅 Jan 2022 – Present

- Designed and deployed 30+ ADF pipelines to automate ingestion from on-premises SQL Server, REST APIs, and flat files into Azure Data Lake Gen2.
- Implemented Medallion Architecture (Bronze, Silver, Gold layers) in Azure Databricks using PySpark for data cleansing, transformation, and enrichment.
- Developed Delta Lake tables to enable ACID transactions and time travel for data consistency.
- Built fact and dimension models in Azure Synapse Analytics to support enterprise reporting.
- Optimized PySpark jobs improving performance by 40% for large-scale data processing (>500GB).
- Integrated CI/CD pipelines with Azure DevOps for automated deployment of ADF pipelines and Databricks notebooks.
- Partnered with Data Scientists and Analysts to provide curated datasets for ML models and BI dashboards.

### Data Engineer
**[Previous Company Name] – [Location]**
📅 Jan 2020 – Dec 2021

- Developed ETL pipelines using Python and SQL to integrate data from multiple relational databases into a central warehouse.
- Worked with AWS S3, Glue, and Redshift for building scalable data solutions.
- Created stored procedures, views, and optimized SQL queries for reporting needs.
- Supported Power BI dashboards by providing curated datasets.

## Education

🎓 **Bachelor of Technology (B.Tech) – Computer Science**
[University Name], [Year of Graduation]

## Projects (Azure-Focused)

### Real-Time Sales Data Platform
- **Description:** Built comprehensive real-time data processing system for retail sales analytics across multiple channels including online, mobile, and in-store transactions. The platform processes millions of daily transactions and provides instant insights for business decision-making.
- **Key Achievements:** Built real-time ingestion pipelines using ADF + Event Hub + Databricks for processing retail sales transactions.
- **Impact:** Designed Synapse Analytics models for reporting sales KPIs, resulting in 40% faster reporting and 99.9% data accuracy.

**Responsibilities:**
- **Data Pipeline Architecture:** Designed and implemented end-to-end real-time data processing architecture using Azure Data Factory, Event Hubs, and Databricks. Created scalable data ingestion pipelines that handle 10M+ daily transactions with sub-second latency requirements.
- **Data Transformation & Enrichment:** Developed complex PySpark transformations in Azure Databricks to cleanse, validate, and enrich sales data from multiple sources. Implemented data quality checks and business rule validations to ensure 99.9% data accuracy across all channels.
- **Real-time Analytics & Monitoring:** Built real-time dashboards and alerting systems using Power BI and Azure Monitor to track sales performance, inventory levels, and system health. Created automated alerts for anomalies and performance degradation to ensure continuous business operations.
- **Data Lake Management:** Implemented Azure Data Lake Gen2 storage with proper partitioning, compression, and lifecycle management strategies. Designed Delta Lake tables for ACID transactions and time travel capabilities to support historical analysis and data recovery.
- **Performance Optimization:** Optimized PySpark jobs and SQL queries to improve processing performance by 60% and reduce costs by 35%. Implemented caching strategies, query optimization, and resource scaling to handle peak load scenarios during Black Friday and holiday seasons.

### Customer 360 Data Lake
- **Description:** Developed unified customer data platform that consolidates customer information from multiple sources including CRM, ERP, marketing automation, and loyalty programs. The system provides a single source of truth for customer data across all business functions.
- **Key Achievements:** Unified customer data from CRM, ERP, and marketing systems into Azure Data Lake.
- **Impact:** Implemented PySpark transformations in Databricks to create a 360° customer profile, enabling personalized marketing campaigns that increased customer engagement by 35%.

**Responsibilities:**
- **Data Integration & ETL:** Designed and implemented comprehensive ETL pipelines using Azure Data Factory to integrate customer data from 15+ source systems including Salesforce, SAP, and marketing platforms. Created automated data validation and reconciliation processes to ensure data consistency and quality across all integrated systems.
- **Customer Data Modeling:** Developed dimensional data models and customer master data management (MDM) solutions using Azure Synapse Analytics. Implemented customer identity resolution algorithms to create unified customer profiles and eliminate duplicate records across different touchpoints.
- **Advanced Analytics & ML:** Built machine learning pipelines in Azure Databricks for customer segmentation, lifetime value prediction, and churn analysis. Implemented real-time scoring models and recommendation engines to enable personalized customer experiences and targeted marketing campaigns.
- **Data Governance & Security:** Established data governance frameworks and implemented role-based access controls using Azure Active Directory and Azure Key Vault. Created data lineage tracking and audit trails to ensure compliance with GDPR and other data privacy regulations.
- **Performance & Scalability:** Optimized data processing workflows to handle 50M+ customer records with sub-minute refresh rates. Implemented data partitioning strategies, indexing, and caching mechanisms to improve query performance by 70% and reduce operational costs by 40%.
