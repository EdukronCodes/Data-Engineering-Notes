# Resume – Azure Data Engineer

**Name:** Dilli Babu  
**Phone:** +91 98765 43219  
**Email:** dilli.data@example.com  
**LinkedIn:** linkedin.com/in/dilli-data-engineer  
**Location:** Chennai, Tamil Nadu  

## Professional Summary

Azure Data Engineer with 3 years of experience in designing, developing, and maintaining retail data platforms on Microsoft Azure. Proficient in Azure Data Factory, Databricks (PySpark), ADLS Gen2, and Synapse Analytics, with strong expertise in ETL/ELT development, data modeling, and performance optimization. Experienced in handling retail data pipelines, customer analytics, and inventory management systems with focus on scalable and reliable data solutions.

## Technical Skills

**Cloud & Data Services:** Azure Data Factory, Azure Databricks, Azure Synapse, ADLS Gen2, Azure SQL, Azure Functions  
**Programming:** Python (Pandas, PySpark), SQL, Java (basic)  
**Data Modeling & Architecture:** Medallion Architecture, Star Schema, SCD (Type 1 & 2), Fact/Dimension modeling, Normalization/Denormalization  
**Orchestration & Automation:** CI/CD with Azure DevOps, GitHub Actions; Trigger-based ADF pipelines; Monitoring & Alerts  
**Visualization & Reporting:** Power BI (Dashboards, Data Models)  
**Tools:** Git, Azure Monitor, JIRA, ServiceNow  

## Professional Experience

### Azure Data Engineer
**[Company Name]** – Chennai | Aug 2021 – Present  

#### Project 1: Retail Electronics & Appliances Data Platform

**Description:**  
Developed a comprehensive retail electronics and appliances data platform processing daily sales, inventory, and customer preference data (~45 GB daily) from multiple electronics retail stores and e-commerce channels. Implemented Medallion Architecture for structured data processing and product performance analysis in Power BI.

**Skills/Tech Stack:**  
Azure Data Factory, Azure Databricks (PySpark), ADLS Gen2, Azure Synapse, Azure SQL, Python, SQL, Azure DevOps

**Responsibilities:**
- Designed and developed end-to-end ETL pipelines using Azure Data Factory to ingest data from SQL Server, APIs, flat files (CSV, JSON, XML), and electronics retail POS systems
- Implemented incremental loading strategies with watermarking and CDC (Change Data Capture) for efficient data refresh (~45 GB daily batch)
- Built PySpark-based transformations in Azure Databricks, including electronics data cleansing, product categorization, and warranty tracking
- Implemented Medallion Architecture (Bronze → Silver → Gold) to streamline data lake organization and improve query performance
- Integrated Azure Synapse Analytics for reporting, creating electronics retail fact/dimension tables in star schema for Power BI dashboards
- Developed robust error handling and logging frameworks using ADF + Azure Monitor, reducing pipeline failures by 45%
- Automated CI/CD deployment of pipelines and notebooks using Azure DevOps, ensuring smooth migration across environments

#### Project 2: Retail Warranty & Service Analytics Platform

**Description:**  
Built a warranty and service analytics platform for retail electronics operations, analyzing warranty claims, service requests, and product reliability data to support customer service and product quality improvements.

**Skills/Tech Stack:**  
Azure Data Factory, Azure Databricks, ADLS Gen2, Synapse Analytics, Azure SQL, Python, SQL, Azure DevOps

**Responsibilities:**
- Analyzed existing warranty and service data workflows and designed Azure-native solutions for service analytics
- Re-engineered service analytics pipelines in ADF with improved error handling and real-time processing capabilities
- Used Databricks PySpark for warranty data transformations and service performance analysis algorithms
- Created warranty and service fact/dimension tables in Synapse with SCD Type 2 handling for historical analysis
- Coordinated with customer service teams to ensure accurate warranty tracking and service performance metrics
- Implemented automated service analytics reporting and trend analysis dashboards

#### Project 3: Retail Product Returns & Refunds Data Pipeline

**Description:**  
Developed data pipelines for retail product returns and refunds processing, handling return data, refund processing, and customer satisfaction metrics for product quality and customer experience improvements.

**Skills/Tech Stack:**  
Azure Data Factory, Databricks, ADLS Gen2, Azure Monitor, ServiceNow, SQL, Python

**Responsibilities:**
- Monitored daily returns and refunds pipeline executions and resolved failures within defined SLAs for customer service teams
- Implemented robust error handling & retry mechanisms in ADF for critical returns and refunds data processing
- Performed data quality checks for returns data (null handling, duplicate removal, schema validation)
- Optimized PySpark jobs and ADF copy activities, reducing execution time by 40% for daily returns reports
- Coordinated with customer service teams to address ad-hoc data requests and ensure timely delivery of returns insights
- Built returns and refunds dashboards and KPI reporting for customer experience optimization

## Education

**B.Tech – Computer Science & Engineering**  
[University Name], 2021

## Certifications

- Microsoft Azure Data Engineer Associate (DP-203)
- Microsoft Azure Fundamentals (AZ-900)
- Databricks Certified Associate Developer
