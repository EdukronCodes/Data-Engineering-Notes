# Resume – Azure Data Engineer

**Name:** Sunand  
**Phone:** +91 98765 43210  
**Email:** sunand.data@example.com  
**LinkedIn:** linkedin.com/in/sunand-data-engineer  
**Location:** Bangalore, Karnataka  

## Professional Summary

Azure Data Engineer with 3 years of experience in designing, developing, and maintaining retail data platforms on Microsoft Azure. Proficient in Azure Data Factory, Databricks (PySpark), ADLS Gen2, and Synapse Analytics, with strong expertise in ETL/ELT development, data modeling, and performance optimization. Experienced in handling retail data pipelines, customer analytics, and inventory management systems with a focus on scalable and reliable data solutions.

## Technical Skills

**Cloud & Data Services:** Azure Data Factory, Azure Databricks, Azure Synapse, ADLS Gen2, Azure SQL, Azure Functions  
**Programming:** Python (Pandas, PySpark), SQL, Scala (basic)  
**Data Modeling & Architecture:** Medallion Architecture, Star Schema, SCD (Type 1 & 2), Fact/Dimension modeling, Normalization/Denormalization  
**Orchestration & Automation:** CI/CD with Azure DevOps, GitHub Actions; Trigger-based ADF pipelines; Monitoring & Alerts  
**Visualization & Reporting:** Power BI (Dashboards, Data Models)  
**Tools:** Git, Azure Monitor, JIRA, ServiceNow  

## Professional Experience

### Azure Data Engineer
**[Company Name]** – Bangalore | Aug 2022 – Present  

#### Project 1: Retail Customer Analytics Platform (End-to-End)

**Description:**  
Developed a comprehensive retail customer analytics platform processing daily customer transactions, loyalty data, and behavioral patterns (~25 GB daily) from multiple retail systems. Implemented Medallion Architecture for structured data processing and real-time customer insights in Power BI.

**Skills/Tech Stack:**  
Azure Data Factory, Azure Databricks (PySpark), ADLS Gen2, Azure Synapse, Azure SQL, Python, SQL, GitHub Actions

**Responsibilities:**
- Designed and developed end-to-end ETL pipelines using Azure Data Factory to ingest data from SQL Server, APIs, flat files (CSV, JSON, XML), and SAP sources
- Implemented incremental loading strategies with watermarking and CDC (Change Data Capture) for efficient data refresh (~25 GB daily batch)
- Built PySpark-based transformations in Azure Databricks, including customer data cleansing, deduplication, and loyalty scoring algorithms
- Implemented Medallion Architecture (Bronze → Silver → Gold) to streamline data lake organization and improve query performance
- Integrated Azure Synapse Analytics for reporting, creating customer fact/dimension tables in star schema for Power BI dashboards
- Developed robust error handling and logging frameworks using ADF + Azure Monitor, reducing pipeline failures by 35%
- Automated CI/CD deployment of pipelines and notebooks using GitHub Actions, ensuring smooth migration across environments

#### Project 2: Retail Inventory Management System Migration

**Description:**  
Migrated legacy retail inventory management system from on-premises Oracle to Azure cloud, modernizing data processing workflows and improving real-time inventory tracking capabilities.

**Skills/Tech Stack:**  
Azure Data Factory, Azure Databricks, ADLS Gen2, Synapse Analytics, SQL Server, Oracle, Python, Azure DevOps

**Responsibilities:**
- Analyzed existing on-prem ETL workflows for inventory data and mapped them to Azure-native solutions
- Re-engineered inventory ETL pipelines in ADF with improved error handling and real-time processing capabilities
- Used Databricks PySpark for heavy inventory transformations and SKU harmonization across multiple warehouses
- Migrated inventory fact/dimension tables into Synapse with SCD Type 2 handling for historical tracking
- Coordinated with retail operations teams to ensure zero data loss during migration and improved inventory visibility

#### Project 3: Retail Sales Pipeline Support & Enhancement

**Description:**  
Provided production support for retail sales data pipelines handling daily transactions, promotions, and store performance data. Enhanced pipeline reliability and optimized performance for better business insights.

**Skills/Tech Stack:**  
Azure Data Factory, Databricks, ADLS Gen2, Azure Monitor, ServiceNow, SQL, Python

**Responsibilities:**
- Monitored daily sales pipeline executions and resolved failures within defined SLAs for retail operations
- Implemented robust error handling & retry mechanisms in ADF for critical sales data processing
- Performed data quality checks for sales data (null handling, duplicate removal, schema validation)
- Optimized PySpark jobs and ADF copy activities, reducing execution time by 30% for daily sales reports
- Coordinated with retail business teams to address ad-hoc data requests and ensure timely delivery of sales insights

## Education

**B.Tech – Computer Science & Engineering**  
[University Name], [Year of Graduation]
