# Resume – Azure Data Engineer

**Name:** Raghavendra P C  
**Phone:** +91 98765 43220  
**Email:** raghavendra.data@example.com  
**LinkedIn:** linkedin.com/in/raghavendra-data-engineer  
**Location:** Bangalore, Karnataka  

## Professional Summary

Azure Data Engineer with 3 years of experience in designing, developing, and maintaining retail data platforms on Microsoft Azure. Proficient in Azure Data Factory, Databricks (PySpark), ADLS Gen2, and Synapse Analytics, with strong expertise in ETL/ELT development, data modeling, and performance optimization. Experienced in handling retail data pipelines, customer analytics, and inventory management systems with focus on scalable and reliable data solutions.

## Technical Skills

**Cloud & Data Services:** Azure Data Factory, Azure Databricks, Azure Synapse, ADLS Gen2, Azure SQL, Azure Functions  
**Programming:** Python (Pandas, PySpark), SQL, Java (basic)  
**Data Modeling & Architecture:** Medallion Architecture, Star Schema, SCD (Type 1 & 2), Fact/Dimension modeling, Normalization/Denormalization  
**Orchestration & Automation:** CI/CD with Azure DevOps, GitHub Actions; Trigger-based ADF pipelines; Monitoring & Alerts  
**Visualization & Reporting:** Power BI (Dashboards, Data Models)  
**Tools:** Git, Azure Monitor, JIRA, ServiceNow  

## Professional Experience

### Azure Data Engineer
**[Company Name]** – Bangalore | Sep 2021 – Present  

#### Project 1: Retail Home & Lifestyle Data Platform

**Description:**  
Developed a comprehensive retail home and lifestyle data platform processing daily sales, inventory, and customer preference data (~35 GB daily) from multiple home goods retail stores and e-commerce channels. Implemented Medallion Architecture for structured data processing and lifestyle trend analysis in Power BI.

**Skills/Tech Stack:**  
Azure Data Factory, Azure Databricks (PySpark), ADLS Gen2, Azure Synapse, Azure SQL, Python, SQL, Azure DevOps

**Responsibilities:**
- Designed and developed end-to-end ETL pipelines using Azure Data Factory to ingest data from SQL Server, APIs, flat files (CSV, JSON, XML), and home retail POS systems
- Implemented incremental loading strategies with watermarking and CDC (Change Data Capture) for efficient data refresh (~35 GB daily batch)
- Built PySpark-based transformations in Azure Databricks, including home goods data cleansing, trend analysis, and seasonal pattern recognition
- Implemented Medallion Architecture (Bronze → Silver → Gold) to streamline data lake organization and improve query performance
- Integrated Azure Synapse Analytics for reporting, creating home retail fact/dimension tables in star schema for Power BI dashboards
- Developed robust error handling and logging frameworks using ADF + Azure Monitor, reducing pipeline failures by 40%
- Automated CI/CD deployment of pipelines and notebooks using Azure DevOps, ensuring smooth migration across environments

#### Project 2: Retail Seasonal & Trend Analytics Platform

**Description:**  
Built a seasonal and trend analytics platform for retail operations, analyzing seasonal patterns, trend forecasting, and demand prediction to support inventory planning and merchandising decisions.

**Skills/Tech Stack:**  
Azure Data Factory, Azure Databricks, ADLS Gen2, Synapse Analytics, Azure SQL, Python, SQL, Azure DevOps

**Responsibilities:**
- Analyzed existing seasonal and trend data workflows and designed Azure-native solutions for trend analytics
- Re-engineered trend analytics pipelines in ADF with improved error handling and real-time processing capabilities
- Used Databricks PySpark for seasonal pattern transformations and trend forecasting algorithms
- Created seasonal and trend fact/dimension tables in Synapse with SCD Type 2 handling for historical analysis
- Coordinated with merchandising teams to ensure accurate trend analysis and seasonal planning insights
- Implemented automated trend reporting and seasonal pattern analysis dashboards

#### Project 3: Retail Store Layout & Space Optimization Data Pipeline

**Description:**  
Developed data pipelines for retail store layout and space optimization, handling store performance data, space utilization metrics, and layout effectiveness analysis for store design improvements.

**Skills/Tech Stack:**  
Azure Data Factory, Databricks, ADLS Gen2, Azure Monitor, ServiceNow, SQL, Python

**Responsibilities:**
- Monitored daily store layout pipeline executions and resolved failures within defined SLAs for store design teams
- Implemented robust error handling & retry mechanisms in ADF for critical store layout data processing
- Performed data quality checks for layout data (null handling, duplicate removal, schema validation)
- Optimized PySpark jobs and ADF copy activities, reducing execution time by 35% for daily layout reports
- Coordinated with store design teams to address ad-hoc data requests and ensure timely delivery of layout insights
- Built store layout optimization dashboards and KPI reporting for space utilization improvements

## Education

**B.Tech – Computer Science & Engineering**  
[University Name], 2021

## Certifications

- Microsoft Azure Data Engineer Associate (DP-203)
- Microsoft Azure Fundamentals (AZ-900)
- Databricks Certified Associate Developer
