I am a **Data Engineer** with over 3 years of experience in building and maintaining data solutions, focusing on technologies like **Databricks**, **Azure Data Factory**, **ADLS Blob Storage**, **PySpark**, **SQL**, and **Python**. My expertise includes developing scalable data pipelines to automate data ingestion, transformation, and loading for large datasets, both in batch and real-time. I have implemented efficient data processing workflows in **PySpark** within **Databricks**, leveraging **ADLS Blob Storage** to handle large-scale data efficiently.

I have been responsible for writing optimized SQL queries for data extraction and transformation from **ADLS Blob Storage**, ensuring high performance for reporting and analytics. In addition, I have built data workflows in **Azure Data Factory** to move data between **ADLS** and various other sources, automating the entire process. Utilizing **Python**, I have scripted and automated transformations on datasets, improving pipeline efficiency while reducing manual intervention.

Throughout my projects, I have ensured smooth collaboration by managing code versioning with **GitHub** and tracking tasks using **Jira** in an agile environment. I have also monitored and optimized **Databricks** clusters for better resource utilization, minimizing costs while ensuring high performance. Furthermore, I have collaborated with cross-functional teams to implement best practices for data storage and processing in **ADLS Blob Storage**, maintaining data quality, accuracy, and consistency across various layers in the architecture.
