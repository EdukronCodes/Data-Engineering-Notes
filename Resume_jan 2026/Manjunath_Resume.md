# Resume – Manjunath (Data Engineer – Azure DevOps → Data Science / MLOps)

## Details
- **Name**: Manjunath  
- **Target Role**: Data Scientist / Azure Data & MLOps Engineer  
- **Experience**: 3 years  
- **Primary Stack**: Azure DevOps, CI/CD Pipelines, Cloud Integration  

## Career Objective
Azure DevOps and Data Engineer with 3 years of experience in CI/CD and cloud integration, looking to transition into Data Science and MLOps. Aiming to combine DevOps discipline, Azure expertise, and emerging GenAI techniques to build reliable ML pipelines and intelligent, agentic AI solutions.

## Roles & Responsibilities
1. Designed and maintained Azure DevOps pipelines for building, testing, and deploying data and ML-related services.
2. Integrated Azure services (Data Lake, Databricks, Functions, AKS) to support data ingestion, processing, and model deployment.
3. Automated infrastructure provisioning via ARM/Bicep/Terraform templates for repeatable environments.
4. Enabled data scientists to package and deploy models consistently across dev, test, and prod environments.
5. Implemented monitoring and logging across Azure resources, with dashboards and alerts for critical KPIs.
6. Supported GenAI experiments by provisioning and configuring Azure OpenAI and related services.
7. Assisted in implementing agent-based workflows where Azure Functions/Logic Apps orchestrate multi-step ML tasks.
8. Enforced security and compliance best practices, including RBAC, Key Vault usage, and network isolation.
9. Documented pipelines, release processes, and platform capabilities.
10. Participated in planning and retrospectives, proposing improvements to deployment and experimentation workflows.

## Skills
- **Azure & DevOps**: Azure DevOps Pipelines, Repos, Boards; ARM/Bicep/Terraform; Azure Functions, AKS, Databricks, Data Factory
- **Data & ML**: Python (basic), model packaging/deployment, data pipeline concepts
- **GenAI & Agentic AI**: Azure OpenAI, prompt engineering, building GenAI web/API services, Azure Functions/Logic Apps for agent flows
- **Other**: Git, monitoring (App Insights, Log Analytics), security, documentation

## Projects

### Project 1: Azure ML CI/CD Framework
- **Title**: Azure ML CI/CD Framework
- **Description**: Implemented a standardized CI/CD framework for deploying ML models and data services on Azure.
- **Skills**: Azure DevOps, YAML pipelines, Docker, AKS, Azure ML/Databricks
- **Roles & Responsibilities**:
  1. Created reusable pipeline templates for build, test, and deployment stages.
  2. Integrated quality gates (tests, style checks, approval steps) before promoting to production.
  3. Automated configuration management via variable groups and Key Vault integration.
  4. Reduced manual deployment effort and errors across multiple ML projects.

### Project 2: GenAI-Powered Analytics Portal
- **Title**: GenAI-Powered Analytics Portal
- **Description**: Supported the development and deployment of an Azure-based GenAI analytics portal that allows users to query data in natural language.
- **Skills**: Azure OpenAI, App Service/AKS, DevOps pipelines, data integration
- **Roles & Responsibilities**:
  1. Configured and secured Azure OpenAI resources and connection settings.
  2. Automated deployment of backend APIs and front-end components via pipelines.
  3. Set up monitoring and logging to capture usage, latency, and errors for ongoing optimization.
  4. Collaborated with data scientists to validate performance and adjust infrastructure as usage grew.

### Project 3: Agentic Orchestration of Data Refresh & Model Retrain
- **Title**: Agentic Orchestration of Data Refresh & Model Retrain
- **Description**: Implemented agent-like workflows that automatically retrain models and refresh dashboards when new data arrives.
- **Skills**: Azure Functions, Logic Apps, Event Grid, Databricks, DevOps
- **Roles & Responsibilities**:
  1. Configured events/triggers on data landing zones to start orchestration workflows.
  2. Chained steps for data validation, feature generation, model retraining, evaluation, and deployment.
  3. Implemented approval steps where required and notifications to stakeholders.
  4. Documented the framework for re-use across multiple analytical use cases.
