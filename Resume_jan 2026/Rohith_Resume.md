# Resume – Rohith (Data Engineer → Data Scientist / GenAI)

## Details
- **Name**: Rohith  
- **Target Role**: Data Scientist / Data Engineer (Foundations & GenAI)  
- **Experience**: Not specified (focus on fundamentals and projects)  
- **Primary Stack**: Data Engineering Fundamentals, SQL, Python  

## Career Objective
Enthusiastic Data Engineer with strong fundamentals in SQL and Python, pursuing a career in Data Science with an emphasis on GenAI. Looking to contribute to teams by building reliable data pipelines, analytical models, and intelligent agents that automate insights and repetitive tasks.

## Roles & Responsibilities
1. Implemented ETL scripts to ingest and preprocess structured and semi-structured data.
2. Wrote SQL queries and views to compute metrics and support dashboards.
3. Performed exploratory data analysis to understand data distributions, anomalies, and relationships.
4. Built small-scale ML models for classification/regression tasks, iterating on features and evaluation metrics.
5. Experimented with LLM APIs for tasks like text summarization, classification, and conversational Q&A over datasets.
6. Built experimental agent workflows that chain data retrieval, computation, and explanation steps triggered by user questions.
7. Maintained code quality via Git and basic testing; documented scripts and usage patterns.
8. Collaborated with mentors/peers to review models and pipelines, incorporating feedback into improved designs.
9. Participated in project planning, break-down of tasks, and agile ceremonies.
10. Continuously upskilled in ML, GenAI, and data engineering best practices via courses and hands-on projects.

## Skills
- **Programming**: Python (Pandas, NumPy, scikit-learn), SQL
- **Data Engineering**: ETL basics, data modeling concepts, simple scheduling/orchestration
- **Data Science**: EDA, feature engineering basics, supervised learning, evaluation (accuracy, F1, RMSE)
- **GenAI & Agentic AI**: LLM APIs, simple RAG prototypes, prompt engineering, multi-step agent POCs
- **Other**: Git, Jupyter, visualization (Matplotlib/Seaborn), communication

## Projects

### Project 1: Customer Segmentation & Targeting
- **Title**: Customer Segmentation & Targeting
- **Description**: Built an end-to-end pipeline to segment customers based on behavior and demographics for targeted marketing.
- **Skills**: Python, SQL, clustering, feature engineering, visualization
- **Roles & Responsibilities**:
  1. Collected and cleaned customer transaction and interaction data.
  2. Engineered features such as RFM metrics, product affinity, and engagement scores.
  3. Applied clustering algorithms (K-Means/others) to group customers and profiled each segment.
  4. Shared insights with stakeholders and suggested segment-specific actions.

### Project 2: GenAI Data Q&A Bot
- **Title**: GenAI Data Q&A Bot
- **Description**: Developed a prototype Q&A bot that answers questions about a dataset (sales/transactions) using natural language.
- **Skills**: Python, SQL, LLM APIs, prompt engineering
- **Roles & Responsibilities**:
  1. Defined a mapping from business terms to SQL queries to fetch relevant data slices.
  2. Built logic to construct prompts that combine user questions with retrieved statistics.
  3. Used an LLM to generate clear explanations and charts (described in text) summarizing results.
  4. Collected user feedback and iterated on query templates and prompts.

### Project 3: Agentic Data Health Checker
- **Title**: Agentic Data Health Checker
- **Description**: Implemented a small agent that checks daily data loads, validations, and metrics, then reports status.
- **Skills**: Python, scheduling (cron/Airflow-lite), basic anomaly detection, LLM summarization
- **Roles & Responsibilities**:
  1. Wrote validation scripts to verify row counts, null rates, and value ranges.
  2. Aggregated results and used an LLM to produce a concise "data health" summary.
  3. Sent the summary via email/Slack to the data team, flagging potential issues with suggested next steps.
  4. Enhanced the agent based on incident post-mortems.
