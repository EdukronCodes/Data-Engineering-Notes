# Resume – Amini (Data Engineer → Data Science / GenAI)

## Details
- **Name**: Amini  
- **Target Role**: Data Scientist / Data Engineer (GenAI & Analytics)  
- **Total Experience**: 3+ years  
- **Primary Stack**: SQL, Python, ETL Pipelines, Azure Data Factory, Databricks  

## Career Objective
Results-driven Data Engineer transitioning into Data Science, with 3+ years of experience designing scalable ETL pipelines, building analytical data models, and optimizing cloud-based data platforms on Azure. Seeking a Data Scientist role where I can apply strong data engineering foundations, statistical analysis, and Generative AI (GenAI) techniques to deliver actionable insights and intelligent, agentic AI solutions for business problems.

## Roles & Responsibilities (Data Science–Oriented)
1. Designed and maintained robust ETL pipelines to ingest, clean, and transform structured and semi-structured data for analytics and machine learning use cases.
2. Developed SQL-based data models and views enabling self-service analysis and BI dashboards for stakeholders across finance, product, and operations.
3. Built PySpark and Python data preparation workflows in Databricks to support feature engineering for predictive and GenAI applications.
4. Collaborated with data scientists to deploy ML models and LLM-powered components into production data pipelines with proper monitoring and logging.
5. Implemented data quality checks, validation rules, and automated alerts to ensure high trust in analytical and AI-driven outputs.
6. Optimized Azure Data Factory pipelines for performance and cost, including partitioning, parallelization, and incremental loading strategies.
7. Developed and maintained reusable data assets, metadata, and documentation to enable discoverability and governance across teams.
8. Experimented with Generative AI (e.g., prompt engineering, embeddings) to build data-enriched LLM workflows for reporting, anomaly explanation, and Q&A over datasets.
9. Integrated agentic AI components that automatically trigger data quality investigations, recompute metrics, or rerun pipelines based on anomalies or business events.
10. Partnered with business stakeholders to translate ambiguous requirements into measurable data science and analytics deliverables.

## Skills
- **Programming & Scripting**: Python (Pandas, PySpark), SQL, Bash
- **Data Engineering**: ETL/ELT, Azure Data Factory, Databricks, Delta Lake, data modeling (star/snowflake)
- **Data Science & Analytics**: Exploratory data analysis, feature engineering, basic ML (regression, classification), time-series analysis
- **GenAI & Agentic AI**: Prompt engineering, retrieval-augmented generation (RAG), building data-aware LLM tools, orchestration of agent workflows for data operations
- **Cloud & Tools**: Azure (ADF, Databricks, Data Lake), Git, CI/CD basics, REST APIs
- **Other**: Data quality, documentation, stakeholder communication, Agile/Scrum

## Projects

### Project 1: Customer Churn Prediction Pipeline
- **Title**: Customer Churn Prediction Pipeline
- **Description**: Built an end-to-end churn prediction pipeline combining ETL, feature engineering, and model scoring to identify at-risk customers for a subscription business.
- **Skills**: Python, SQL, Azure Data Factory, Databricks, ML (classification), feature engineering
- **Roles & Responsibilities**:
  1. Designed and implemented ETL pipelines to consolidate customer, billing, and interaction data from multiple source systems.
  2. Engineered features around usage, ticket history, and payment behavior and exposed them as reusable data sets.
  3. Collaborated with data scientists to train and evaluate churn models, then productionized the scoring pipeline in Databricks.
  4. Implemented model monitoring dashboards with drift checks and automated alerts when performance degraded.

### Project 2: GenAI Analytics Assistant for Business Users
- **Title**: GenAI Analytics Assistant for Business Users
- **Description**: Developed a Generative AI–powered assistant that allows business users to query data in natural language and receive narrative insights with supporting tables and charts.
- **Skills**: Python, SQL, Databricks, LLM APIs, RAG, prompt engineering, vector stores
- **Roles & Responsibilities**:
  1. Prepared semantic layers and curated tables optimized for consumption by the GenAI assistant.
  2. Built a RAG pipeline to ground LLM responses in governed analytical data, including embeddings and similarity search over metrics documentation.
  3. Designed prompt templates to generate SQL queries from user questions, validate them, and execute safely against read-only warehouses.
  4. Logged conversations, queries, and feedback to continuously refine prompts and improve answer quality.

### Project 3: Agentic AI for Data Quality & Pipeline Reliability
- **Title**: Agentic AI for Data Quality & Pipeline Reliability
- **Description**: Implemented agent-style workflows that automatically investigate and remediate common data quality issues in Azure-based pipelines.
- **Skills**: Python, Azure Data Factory, Databricks, monitoring/alerting, agentic AI patterns
- **Roles & Responsibilities**:
  1. Built rule-based and LLM-assisted agents that analyze failed pipeline runs and data anomalies to suggest root causes.
  2. Automated corrective actions such as backfilling missing partitions or re-triggering upstream jobs after resolving source issues.
  3. Created dashboards and reports summarizing incident trends, resolution times, and pipeline health metrics.
