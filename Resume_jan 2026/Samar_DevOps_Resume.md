# Resume – Samar (DevOps Engineer → MLOps / GenAI Platforms)

## Details
- **Name**: Samar  
- **Target Role**: DevOps / MLOps Engineer for Data Science & GenAI  
- **Experience**: Not specified (1–2+ years assumed)  
- **Primary Stack**: CI/CD, Cloud Infrastructure, Automation  

## Career Objective
DevOps Engineer focusing on CI/CD and cloud infrastructure, seeking to specialize in MLOps and GenAI platform engineering. Motivated to build reliable, automated pipelines and environments that empower data scientists to deploy ML and agentic AI workloads at scale.

## Roles & Responsibilities
1. Implemented CI/CD pipelines to build, test, and deploy data and ML-related services.
2. Managed cloud resources (compute, storage, networking) for data engineering and data science teams.
3. Automated infrastructure provisioning and configuration using scripts and templates.
4. Containerized applications and simple ML services using Docker and managed their lifecycle.
5. Set up monitoring and logging solutions for critical services and tuned alerts for reliability.
6. Collaborated with data teams to define deployment strategies for models, LLM services, and APIs.
7. Introduced infrastructure support for GenAI workloads, including GPU-enabled instances and secure access to LLM providers.
8. Helped design agentic AI workflows that tie infrastructure events (failures, scale needs) to automated actions.
9. Documented platform components, deployment runbooks, and troubleshooting steps.
10. Participated in security reviews, applying best practices for secrets management and access control.

## Skills
- **DevOps & MLOps**: CI/CD, Docker, basic Kubernetes, infrastructure scripting, deployment patterns for ML/GenAI
- **Cloud**: AWS/Azure/GCP basics, networking, load balancers, storage
- **Tooling**: Git, Terraform/CloudFormation (optional), monitoring (Prometheus/Grafana, CloudWatch)
- **GenAI & Agentic AI**: Deploying LLM services, configuring autoscaling, integrating with vector stores/feature stores, event-driven agents
- **Other**: Linux administration, scripting, documentation, collaboration

## Projects

### Project 1: ML API CI/CD & Deployment
- **Title**: ML API CI/CD & Deployment
- **Description**: Built CI/CD pipelines and infrastructure to deploy Python-based ML APIs in a reliable, repeatable way.
- **Skills**: Git, CI/CD (GitHub Actions/Jenkins), Docker, Python, FastAPI
- **Roles & Responsibilities**:
  1. Automated build, test, and deployment steps triggered on code changes.
  2. Implemented environment-specific configurations and secrets handling.
  3. Deployed services to cloud VMs/containers and set up load balancing and health checks.
  4. Monitored deployments and implemented rollback strategies.

### Project 2: GenAI Model Hosting Environment
- **Title**: GenAI Model Hosting Environment
- **Description**: Set up a scalable environment for hosting GenAI services exposed to internal tools and microservices.
- **Skills**: Docker, cloud infra, LLM APIs, security, monitoring
- **Roles & Responsibilities**:
  1. Provisioned instances with GPU/CPU profiles suited to GenAI workloads.
  2. Configured secure access to external LLM gateways, ensuring key rotation and auditing.
  3. Established dashboards tracking request volume, latency, and cost per feature.
  4. Worked with data scientists to validate performance and optimize resource allocation.

### Project 3: Agentic Infra Automation Bot
- **Title**: Agentic Infra Automation Bot
- **Description**: Created a bot that observes infra metrics and Git events, recommending or carrying out actions like scaling or restarting services.
- **Skills**: Scripting (Python/Bash), monitoring APIs, webhooks, agent logic
- **Roles & Responsibilities**:
  1. Integrated monitoring tools with webhooks to trigger bot actions when thresholds were crossed.
  2. Implemented decision logic for actions (e.g., scale up/down, restart pods/services, notify owners).
  3. Logged all actions for auditability and continuous improvement.
  4. Documented workflows and trained the team on using and extending the bot.
