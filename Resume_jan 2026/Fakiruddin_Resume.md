# Resume – Fakiruddin (Data Engineer → Data Science / GenAI)

## Details
- **Name**: Fakiruddin  
- **Target Role**: Data Scientist / Data Engineer (Cloud & GenAI)  
- **Experience**: 2+ years  
- **Primary Stack**: SQL, Python, ETL, Cloud Data Platforms  

## Career Objective
Cloud-oriented Data Engineer with 2+ years of experience designing and operating ETL pipelines, aspiring to transition into Data Science with a focus on GenAI-enhanced analytics. Interested in building robust data foundations, predictive models, and intelligent agents that automate insight generation and operational decision-making.

## Roles & Responsibilities
1. Developed and maintained ETL processes to collect, transform, and load data from multiple operational systems into cloud data warehouses.
2. Wrote complex SQL queries and views to support BI reporting, self-service analytics, and downstream ML pipelines.
3. Implemented Python-based data processing and validation scripts to ensure accuracy and consistency.
4. Collaborated with analysts and data scientists to define data contracts and feature requirements.
5. Monitored pipeline health and resolved data quality issues through root-cause analysis and corrective actions.
6. Prototyped ML models for classification and regression tasks using scikit-learn and evaluated performance with appropriate metrics.
7. Built early GenAI POCs that used LLMs to summarize datasets, generate report drafts, and assist with ad-hoc analysis.
8. Implemented basic agentic workflows to orchestrate multi-step data tasks (e.g., extraction, cleaning, modeling) triggered by schedules or events.
9. Documented schemas, pipelines, and data lineage for transparency and governance.
10. Participated in sprint planning, code reviews, and continuous improvement initiatives.

## Skills
- **Data Engineering**: SQL, ETL/ELT, data warehousing, cloud data platforms (BigQuery/Redshift/Snowflake-like)
- **Programming**: Python (Pandas, NumPy), shell scripting, basic Spark
- **Data Science**: ML basics (classification/regression), feature engineering, evaluation, simple visualizations
- **GenAI & Agentic AI**: LLM APIs, prompt engineering, report generation, simple multi-tool agents for data workflows
- **Other**: Git, CI basics, documentation, stakeholder communication

## Projects

### Project 1: Centralized Customer Data Warehouse
- **Title**: Centralized Customer Data Warehouse
- **Description**: Consolidated customer data from CRM, billing, and support systems into a unified warehouse for analytics and modeling.
- **Skills**: SQL, ETL, cloud DW, data modeling
- **Roles & Responsibilities**:
  1. Designed star-schema models for customer, product, and transaction data.
  2. Developed ETL pipelines to keep the warehouse up to date with near-real-time replication.
  3. Implemented data quality checks and reconciliation reports to ensure accuracy.
  4. Enabled analysts to self-serve metrics with curated views and documentation.

### Project 2: GenAI Reporting Companion
- **Title**: GenAI Reporting Companion
- **Description**: Built a GenAI tool that generates narrative summaries of weekly business performance using warehouse data.
- **Skills**: Python, LLM APIs, SQL, prompt engineering
- **Roles & Responsibilities**:
  1. Created SQL queries to extract key KPIs and trends for the reporting period.
  2. Designed prompts that feed metrics into an LLM to generate human-readable summaries and insights.
  3. Integrated the tool into the reporting workflow via a simple CLI/UI, reducing manual report writing time.
  4. Collected feedback to refine prompts and improve relevance/accuracy of generated narratives.

### Project 3: Agentic Data Task Orchestrator
- **Title**: Agentic Data Task Orchestrator
- **Description**: Implemented a lightweight agent system that coordinates extraction, validation, and notification tasks for daily data jobs.
- **Skills**: Python, scheduling, message queues/emails, agent pattern design
- **Roles & Responsibilities**:
  1. Defined modular tasks (extract, validate, publish, notify) with clear inputs and outputs.
  2. Built an agent that decides which tasks to run based on job history and validation results.
  3. Implemented error handling and automatic retries with escalation if repeated failures occur.
  4. Documented architecture and onboarded other team members to extend the system.
